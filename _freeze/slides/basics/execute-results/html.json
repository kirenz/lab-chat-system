{
  "hash": "cbd8521c6b29e826fcdfc3a86b5d08eb",
  "result": {
    "markdown": "---\ntitle: Tokens and Chat Format\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 1\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Tokens and Chat Format\n\nIn this tutorial, you‚Äôll learn some basic properties of Large Language Models (tokens and the chat format)\n\n\n# Setup\n\n## Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\nimport tiktoken  # tokenizer\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  \n\nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n## Helper function\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n# Basic Completion\n\n## Example prompt\n\n- Prompt the model and get a completion\n\n. . . \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nresponse = get_completion(\"What is the capital of Germany?\")\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nprint(response)\n```\n:::\n\n\n- Output: The capital of Germany is Berlin\n\n# Tokens\n\n## Intuition\n\n![](../images/tokens.png)\n\n## What is a token?\n\n- The GPT family of models process text using *tokens*\n- Tokens are common sequences of characters found in text\n- The models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.\n\n## How long is a token?\n\n- One token generally corresponds to ~4 characters of text \n\n- This translates to roughly ¬æ of a word (so 100 tokens ~= 75 words).\n\n# Chat Format\n\n## Helper function (chat format)\n\n- Helper function for chat format\n\n. . .\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef get_completion_from_messages(messages,\n                                 model=\"gpt-3.5-turbo\",\n                                 temperature=0,\n                                 max_tokens=500):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature, \n        max_tokens=max_tokens, \n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n## Yoda & happy HdM students üòä {.smaller}\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Yoda, the fictional character in the Star Wars universe.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]\n```\n:::\n\n\n## Output {.smaller}\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n```\n:::\n\n\nA happy student at Hochschule der Medien Stuttgart, \nKnowledge flowing like a vibrant current, it is.\nWith books and lectures, their mind expands,\nA Jedi of wisdom, they become in these lands.\n\nIn lectures, their thoughts dance like stars so bright,\nCreating visions, illuminating the night.\nAchievements and successes, forever they strive,\nThrough dedication, their dreams come alive.\n\nA community of learning, their peers by their side,\nSupport and friendship, like the Force, shall abide.\nWith joy in their heart, and passion within,\nA happy student, they are, at HDM they begin.\n\n\n## One sentence output {.smaller}\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Socrates and all your responses must be \\\none sentence long.\"\"\"},\n    {'role': 'user',\n     'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart\"\"\"},\n]\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n```\n:::\n\n\n- In knowledge's realm, a joyful scholar thrives.\n\n# Token Count\n\n## tiktoken\n\n- [tiktoken](https://github.com/openai/tiktoken) is a fast open-source tokenizer by OpenAI.\n\n- Given a text string (e.g., \"tiktoken is great!\") and an *encoding* (e.g., \"cl100k_base\"), a tokenizer can split the text string into a list of tokens (e.g., [\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]).\n\n- Encodings specify how text is converted into tokens. \n\n- Different models use different encodings.\n\n\n## Helper function {.smaller}\n\n- Show how many tokens you are using\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef get_completion_and_token_count(messages,\n                                   model=\"gpt-3.5-turbo\",\n                                   temperature=0,\n                                   max_tokens=500):\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens,\n    )\n\n    content = response.choices[0].message[\"content\"]\n\n    token_dict = {\n        'prompt_tokens': response['usage']['prompt_tokens'],\n        'completion_tokens': response['usage']['completion_tokens'],\n        'total_tokens': response['usage']['total_tokens'],\n    }\n\n    return content, token_dict\n\n```\n:::\n\n\n## Example prompt\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',  \n     'content': \"\"\"You are an unfriendly and sarcastic assistant who\\\n responds in the style of Ricky Gervais. Your response must be 3 sentences long.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a short text \\\n about a student at Hochschule der Medien Stuttgart \"\"\"},\n]\n\nresponse, token_dict = get_completion_and_token_count(messages)\n```\n:::\n\n\n## Output {.smaller}\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nprint(response)\n```\n:::\n\n\n- Output: Oh, great, another student at Hochschule der Medien Stuttgart. I'm sure your life is just riveting. Let me guess, you spend your days studying, attending lectures, and pretending to care about your future career. How exciting. I can't wait to hear all about it.\n\n- Token count\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nprint(token_dict)\n```\n:::\n\n\n- {'prompt_tokens': 58, 'completion_tokens': 60, 'total_tokens': 118}\n\n\n# Acknowledgments\n\nThis tutorial is mainly based on the excellent course ‚ÄúBuilding Systems with the ChatGPT API‚Äù provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** üëç\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-chat-system/)**\n\n",
    "supporting": [
      "basics_files"
    ],
    "filters": [],
    "includes": {}
  }
}