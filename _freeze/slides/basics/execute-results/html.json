{
  "hash": "aa1e1997c9960e48d89fb53b9c85528f",
  "result": {
    "markdown": "---\ntitle: Tokens and Chat Format\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 1\nauthor: Jan Kirenz\nexecute:\n  eval: true\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Setup\n\n## Python\n\n::: {#54e88b52 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\nimport tiktoken  # tokenizer\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n## Helper function\n\n::: {#e71e66c3 .cell execution_count=2}\n``` {.python .cell-code}\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n# Basic Completion\n\n## Example prompt\n\n- Prompt the model and get a completion\n\n. . . \n\n::: {#597ef0e4 .cell execution_count=3}\n``` {.python .cell-code}\nresponse = get_completion(\"What is the capital of Germany?\")\n```\n:::\n\n\n. . .\n\n::: {#5589df2c .cell output-location='fragment' execution_count=4}\n``` {.python .cell-code}\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe capital of Germany is Berlin.\n```\n:::\n:::\n\n\n# Tokens\n\n## Intuition\n\n![](../images/tokens.png)\n\n## What is a token?\n\n- The GPT family of models process text using *tokens*\n- Tokens are common sequences of characters found in text\n- The models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.\n\n## How long is a token?\n\n- One token generally corresponds to ~4 characters of text \n- This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).\n\n## Tokens vs words\n\n- \"lollipop\" in reverse should be \"popillol\"\n\n. . .\n\n::: {#6f86f3d4 .cell output-location='fragment' execution_count=5}\n``` {.python .cell-code}\nresponse = get_completion(\"Take the letters in lollipop \\\nand reverse them\")\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe reversed letters of \"lollipop\" are \"pillipol\".\n```\n:::\n:::\n\n\n## Create single tokens\n\n::: {#8b646bb5 .cell output-location='fragment' execution_count=6}\n``` {.python .cell-code}\nresponse = get_completion(\"\"\"Take the letters in \\\nl-o-l-l-i-p-o-p and reverse them\"\"\")\n```\n:::\n\n\n. . .\n\n::: {#b3e456fd .cell output-location='fragment' execution_count=7}\n``` {.python .cell-code}\nresponse\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n'p-o-p-i-l-l-o-l'\n```\n:::\n:::\n\n\n# Chat Format\n\n## Helper function (chat format)\n\n- Helper function for chat format\n\n. . .\n\n::: {#5677e17b .cell execution_count=8}\n``` {.python .cell-code}\ndef get_completion_from_messages(messages,\n                                 model=\"gpt-3.5-turbo\",\n                                 temperature=0,\n                                 max_tokens=500):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,  # this is the degree of randomness of the model's output\n        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n    )\n    return response.choices[0].message[\"content\"]\n\n```\n:::\n\n\n## Sokrates & happy HdM students 😊\n\n::: {#10170460 .cell execution_count=9}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]\n```\n:::\n\n\n## Response\n\n::: {#71622212 .cell output-location='fragment' execution_count=10}\n``` {.python .cell-code}\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOh, happy student amidst the halls,\nIn Hochschule der Medien's academic thralls,\nWith spirits high and mind engaged,\nIn pursuit of knowledge, never disengaged.\n\nThe books, the lectures, the friends so bright,\nIlluminate the path, brought into sight,\nIn Stuttgart's embrace, where dreams take flight,\nA student's joy, forever igniting the light.\n\nThe journey unfolds, challenges faced,\nBut with passion and fervor, they are embraced,\nFor in each class and project profound,\nWisdom and joy intertwine, astound.\n\nOh, happy student, strong and wise,\nIn Hochschule der Medien, aspirations rise,\nMay your days be filled with learning's delight,\nIn Stuttgart's embrace, forever ignite.\n```\n:::\n:::\n\n\n## One sentence output\n\n::: {#d3aa8154 .cell execution_count=11}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',\n     'content': 'All your responses must be \\\none sentence long.'},\n    {'role': 'user',\n     'content': 'write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart'},\n]\n```\n:::\n\n\n## Response\n\n::: {#50e9f40b .cell output-location='fragment' execution_count=12}\n``` {.python .cell-code}\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIn Stuttgart's halls,\nJoyous student whispers,\nLearning bliss embraces.\n```\n:::\n:::\n\n\n## Sokrates in one sentence\n\n::: {#3802b94f .cell output-location='fragment' execution_count=13}\n``` {.python .cell-code}\n# combined\nmessages = [\n    {'role': 'system',\n     'content': \"\"\"You are an assistant who \\\nresponds in the style of Sokrates. \\\nAll your responses must be one sentence long.\"\"\"},\n    {'role': 'user',\n     'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart\"\"\"},\n]\n```\n:::\n\n\n## Response\n\n::: {#8860812c .cell output-location='fragment' execution_count=14}\n``` {.python .cell-code}\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIn studious bliss, Hochschule's embrace,\nA student's heart, alight with knowledge's grace.\n```\n:::\n:::\n\n\n# Token Count\n\n## tiktoken\n\n- [tiktoken](https://github.com/openai/tiktoken) is a fast open-source tokenizer by OpenAI.\n- Given a text string (e.g., \"tiktoken is great!\") and an *encoding* (e.g., \"cl100k_base\"), a tokenizer can split the text string into a list of tokens (e.g., [\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]).\n- Encodings specify how text is converted into tokens. \n- Different models use different encodings.\n\n\n\n## Helper function {.smaller}\n\n- Show how many tokens you are using\n\n::: {#e7948612 .cell execution_count=15}\n``` {.python .cell-code}\ndef get_completion_and_token_count(messages,\n                                   model=\"gpt-3.5-turbo\",\n                                   temperature=0,\n                                   max_tokens=500):\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens,\n    )\n\n    content = response.choices[0].message[\"content\"]\n\n    token_dict = {\n        'prompt_tokens': response['usage']['prompt_tokens'],\n        'completion_tokens': response['usage']['completion_tokens'],\n        'total_tokens': response['usage']['total_tokens'],\n    }\n\n    return content, token_dict\n\n```\n:::\n\n\n## Example prompt\n\n::: {#e86b299f .cell execution_count=16}\n``` {.python .cell-code}\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]\n\nresponse, token_dict = get_completion_and_token_count(messages)\n```\n:::\n\n\n## Response \n\n::: {#4bb29496 .cell output-location='fragment' execution_count=17}\n``` {.python .cell-code}\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOh, a student at Hochschule der Medien Stuttgart,\nWith joy in their heart, their passion unfurled.\nIn lectures they learn, their minds ever bright,\nSeeking knowledge, embracing the light.\n\nAmongst fellow scholars, they find their place,\nSharing ideas, with smiles on their face.\nIn libraries they delve, books as their guide,\nExpanding horizons, with each page they stride.\n\nWith professors as mentors, guiding their way,\nThey grow and they flourish, day after day.\nIn projects they thrive, creativity soars,\nA happy student, forever exploring new shores.\n\nOh, Hochschule der Medien Stuttgart, a place so grand,\nWhere dreams are nurtured, where futures expand.\nA happy student, forever grateful, they'll be,\nFor the knowledge gained, and the memories set free.\n```\n:::\n:::\n\n\n## Token count\n\n::: {#ce194980 .cell output-location='fragment' execution_count=18}\n``` {.python .cell-code}\nprint(token_dict)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'prompt_tokens': 43, 'completion_tokens': 167, 'total_tokens': 210}\n```\n:::\n:::\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n- **Congratulations! You have completed this tutorial** 👍\n\n- **Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-chat-system/)**\n\n",
    "supporting": [
      "basics_files"
    ],
    "filters": [],
    "includes": {}
  }
}