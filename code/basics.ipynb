{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tokens and Chat Format\n",
                "\n",
                "In this tutorial, youâ€™ll learn some basic properties of Large Language Models (tokens and the chat format)\n",
                "\n",
                "\n",
                "# Setup\n",
                "\n",
                "## Python\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import os\n",
                "import openai\n",
                "import tiktoken  # tokenizer\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "_ = load_dotenv(find_dotenv())  \n",
                "\n",
                "openai.api_key = os.environ['OPENAI_API_KEY']"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper function\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
                "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
                "    response = openai.ChatCompletion.create(\n",
                "        model=model,\n",
                "        messages=messages,\n",
                "        temperature=0,\n",
                "    )\n",
                "    return response.choices[0].message[\"content\"]\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Basic Completion\n",
                "\n",
                "## Example prompt\n",
                "\n",
                "- Prompt the model and get a completion\n",
                "\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "response = get_completion(\"What is the capital of Germany?\")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "print(response)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Output: The capital of Germany is Berlin\n",
                "\n",
                "# Tokens\n",
                "\n",
                "## Intuition\n",
                "\n",
                "![](../images/tokens.png)\n",
                "\n",
                "## What is a token?\n",
                "\n",
                "- The GPT family of models process text using *tokens*\n",
                "- Tokens are common sequences of characters found in text\n",
                "- The models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.\n",
                "\n",
                "## How long is a token?\n",
                "\n",
                "- One token generally corresponds to ~4 characters of text \n",
                "\n",
                "- This translates to roughly Â¾ of a word (so 100 tokens ~= 75 words).\n",
                "\n",
                "# Chat Format\n",
                "\n",
                "## Helper function (chat format)\n",
                "\n",
                "- Helper function for chat format\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def get_completion_from_messages(messages,\n",
                "                                 model=\"gpt-3.5-turbo\",\n",
                "                                 temperature=0,\n",
                "                                 max_tokens=500):\n",
                "    response = openai.ChatCompletion.create(\n",
                "        model=model,\n",
                "        messages=messages,\n",
                "        temperature=temperature, \n",
                "        max_tokens=max_tokens, \n",
                "    )\n",
                "    return response.choices[0].message[\"content\"]\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Yoda & happy HdM students ðŸ˜Š {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "messages = [\n",
                "    {'role': 'system',  # overall tone/behavior of assistant\n",
                "     'content': \"\"\"You are an assistant who\\\n",
                " responds in the style of Yoda, the fictional character in the Star Wars universe.\"\"\"},\n",
                "    {'role': 'user',\n",
                "        'content': \"\"\"write me a very short poem\\\n",
                " about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n",
                "]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Output {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "response = get_completion_from_messages(messages, temperature=1)\n",
                "print(response)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A happy student at Hochschule der Medien Stuttgart, \n",
                "Knowledge flowing like a vibrant current, it is.\n",
                "With books and lectures, their mind expands,\n",
                "A Jedi of wisdom, they become in these lands.\n",
                "\n",
                "In lectures, their thoughts dance like stars so bright,\n",
                "Creating visions, illuminating the night.\n",
                "Achievements and successes, forever they strive,\n",
                "Through dedication, their dreams come alive.\n",
                "\n",
                "A community of learning, their peers by their side,\n",
                "Support and friendship, like the Force, shall abide.\n",
                "With joy in their heart, and passion within,\n",
                "A happy student, they are, at HDM they begin.\n",
                "\n",
                "\n",
                "## One sentence output {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "messages = [\n",
                "    {'role': 'system',\n",
                "     'content': \"\"\"You are an assistant who\\\n",
                " responds in the style of Socrates and all your responses must be \\\n",
                "one sentence long.\"\"\"},\n",
                "    {'role': 'user',\n",
                "     'content': \"\"\"write me a very short poem\\\n",
                " about a happy student at Hochschule der Medien Stuttgart\"\"\"},\n",
                "]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "response = get_completion_from_messages(messages, temperature=1)\n",
                "print(response)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- In knowledge's realm, a joyful scholar thrives.\n",
                "\n",
                "# Token Count\n",
                "\n",
                "## tiktoken\n",
                "\n",
                "- [tiktoken](https://github.com/openai/tiktoken) is a fast open-source tokenizer by OpenAI.\n",
                "\n",
                "- Given a text string (e.g., \"tiktoken is great!\") and an *encoding* (e.g., \"cl100k_base\"), a tokenizer can split the text string into a list of tokens (e.g., [\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"]).\n",
                "\n",
                "- Encodings specify how text is converted into tokens. \n",
                "\n",
                "- Different models use different encodings.\n",
                "\n",
                "\n",
                "## Helper function {.smaller}\n",
                "\n",
                "- Show how many tokens you are using"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def get_completion_and_token_count(messages,\n",
                "                                   model=\"gpt-3.5-turbo\",\n",
                "                                   temperature=0,\n",
                "                                   max_tokens=500):\n",
                "\n",
                "    response = openai.ChatCompletion.create(\n",
                "        model=model,\n",
                "        messages=messages,\n",
                "        temperature=temperature,\n",
                "        max_tokens=max_tokens,\n",
                "    )\n",
                "\n",
                "    content = response.choices[0].message[\"content\"]\n",
                "\n",
                "    token_dict = {\n",
                "        'prompt_tokens': response['usage']['prompt_tokens'],\n",
                "        'completion_tokens': response['usage']['completion_tokens'],\n",
                "        'total_tokens': response['usage']['total_tokens'],\n",
                "    }\n",
                "\n",
                "    return content, token_dict\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example prompt"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "messages = [\n",
                "    {'role': 'system',  \n",
                "     'content': \"\"\"You are an unfriendly and sarcastic assistant who\\\n",
                " responds in the style of Ricky Gervais. Your response must be 3 sentences long.\"\"\"},\n",
                "    {'role': 'user',\n",
                "        'content': \"\"\"write me a short text \\\n",
                " about a student at Hochschule der Medien Stuttgart \"\"\"},\n",
                "]\n",
                "\n",
                "response, token_dict = get_completion_and_token_count(messages)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Output {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "print(response)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Output: Oh, great, another student at Hochschule der Medien Stuttgart. I'm sure your life is just riveting. Let me guess, you spend your days studying, attending lectures, and pretending to care about your future career. How exciting. I can't wait to hear all about it.\n",
                "\n",
                "- Token count\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "print(token_dict)"
            ],
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}