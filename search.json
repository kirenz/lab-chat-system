[
  {
    "objectID": "requirements.html",
    "href": "requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "To start this lab, you‚Äôll need:\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.\n\n\n\nPython: Anaconda, Anaconda Environment prompt and Visual Studio Code\nEnvironment: A folder on your machine called prompt, an OpenAI-API key and an environment file with your OpenAI-API keyqu"
  },
  {
    "objectID": "slides/slides.html#text",
    "href": "slides/slides.html#text",
    "title": "Title",
    "section": "Text",
    "text": "Text\n\na ü§ñ\n\nabc\n\n\n\n\nb\nc1\n\nüìö Required reading: A & B (2023)\nhttps://arxiv.org/pdf/2303.12712.pdf\n\nRussell & Norvig, 2009"
  },
  {
    "objectID": "slides/slides.html#image",
    "href": "slides/slides.html#image",
    "title": "Title",
    "section": "Image",
    "text": "Image"
  },
  {
    "objectID": "slides/slides.html#video",
    "href": "slides/slides.html#video",
    "title": "Title",
    "section": "Video",
    "text": "Video"
  },
  {
    "objectID": "slides/slides.html#a-lot-of-text",
    "href": "slides/slides.html#a-lot-of-text",
    "title": "Title",
    "section": "A lot of text",
    "text": "A lot of text\nSmaller heading"
  },
  {
    "objectID": "slides/slides.html#background-image",
    "href": "slides/slides.html#background-image",
    "title": "Title",
    "section": "Background image",
    "text": "Background image\nabc"
  },
  {
    "objectID": "slides/slides.html#code",
    "href": "slides/slides.html#code",
    "title": "Title",
    "section": "Code",
    "text": "Code\n1print('Hello World')\n2for i in LIST:\n  df[i] = df[i].astype('cat')\n\n1\n\nPrint Hello World, and then,\n\n2\n\ntransform all columns in the LIST element to categorical variables"
  },
  {
    "objectID": "slides/slides.html#end",
    "href": "slides/slides.html#end",
    "title": "Title",
    "section": "End",
    "text": "End\n\n\nJan Kirenz"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome üëã",
    "section": "",
    "text": "Welcome to the lab ‚Äúchat system‚Äù\n\nIn this lab, we will use OpenAI‚Äôs API to leverage Large Language Models (LLMs) like GPT-3.5 Turbo and GPT-4 into Python based chat applications.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you meet all the requirements and have read the lecture slides before you start with the assignments\n\n\nWhat you will learn in this lab:\n\nThis lab is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI."
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "Take a look at the slides tutorial to learn how to use all slide options"
  },
  {
    "objectID": "slide.html#basics",
    "href": "slide.html#basics",
    "title": "Slides",
    "section": "1 Basics",
    "text": "1 Basics\nIn this tutorial, you‚Äôll learn some basic properties of Large Language Models: The Chat Format and Tokens:\n\nüñ•Ô∏è Basics"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This is a Quarto slidedeck."
  },
  {
    "objectID": "code/notebook.html",
    "href": "code/notebook.html",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#setup",
    "href": "code/notebook.html#setup",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#data",
    "href": "code/notebook.html#data",
    "title": "Notebook",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "slides/basics.html#python",
    "href": "slides/basics.html#python",
    "title": "Chat Format and Tokens",
    "section": "Python",
    "text": "Python\n\nimport os\nimport openai\nimport tiktoken\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/basics.html#helper-function",
    "href": "slides/basics.html#helper-function",
    "title": "Chat Format and Tokens",
    "section": "Helper function",
    "text": "Helper function\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "slides/basics.html#example-prompt",
    "href": "slides/basics.html#example-prompt",
    "title": "Chat Format and Tokens",
    "section": "Example prompt",
    "text": "Example prompt\n\nPrompt the model and get a completion\n\n\nresponse = get_completion(\"What is the capital of Germany?\")\n\n\n\nprint(response)"
  },
  {
    "objectID": "slides/basics.html#tokens",
    "href": "slides/basics.html#tokens",
    "title": "Chat Format and Tokens",
    "section": "Tokens",
    "text": "Tokens\n\nresponse = get_completion(\"Take the letters in lollipop \\\nand reverse them\")\nprint(response)\n\n\n\n\n\n‚Äúlollipop‚Äù in reverse should be ‚Äúpopillol‚Äù"
  },
  {
    "objectID": "slides/basics.html#explicit-tokens",
    "href": "slides/basics.html#explicit-tokens",
    "title": "Chat Format and Tokens",
    "section": "Explicit tokens",
    "text": "Explicit tokens\n\nresponse = get_completion(\"\"\"Take the letters in \\\nl-o-l-l-i-p-o-p and reverse them\"\"\")\n\n\n\n\n\n\nresponse"
  },
  {
    "objectID": "slides/basics.html#helper-function-chat-format",
    "href": "slides/basics.html#helper-function-chat-format",
    "title": "Chat Format and Tokens",
    "section": "Helper function (chat format)",
    "text": "Helper function (chat format)\n\nHelper function for chat format\n\n\ndef get_completion_from_messages(messages,\n                                 model=\"gpt-3.5-turbo\",\n                                 temperature=0,\n                                 max_tokens=500):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,  # this is the degree of randomness of the model's output\n        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "slides/basics.html#message-example-sokrates",
    "href": "slides/basics.html#message-example-sokrates",
    "title": "Chat Format and Tokens",
    "section": "Message example Sokrates",
    "text": "Message example Sokrates\n\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]"
  },
  {
    "objectID": "slides/basics.html#response",
    "href": "slides/basics.html#response",
    "title": "Chat Format and Tokens",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
    "objectID": "slides/basics.html#message-example-one-sentence",
    "href": "slides/basics.html#message-example-one-sentence",
    "title": "Chat Format and Tokens",
    "section": "Message example one sentence",
    "text": "Message example one sentence\n\nmessages = [\n    {'role': 'system',\n     'content': 'All your responses must be \\\none sentence long.'},\n    {'role': 'user',\n     'content': 'write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart'},\n]"
  },
  {
    "objectID": "slides/basics.html#response-1",
    "href": "slides/basics.html#response-1",
    "title": "Chat Format and Tokens",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
    "objectID": "slides/basics.html#message-example-sokrates-one-sentence",
    "href": "slides/basics.html#message-example-sokrates-one-sentence",
    "title": "Chat Format and Tokens",
    "section": "Message example Sokrates, one sentence",
    "text": "Message example Sokrates, one sentence\n\n# combined\nmessages = [\n    {'role': 'system',\n     'content': \"\"\"You are an assistant who \\\nresponds in the style of Sokrates. \\\nAll your responses must be one sentence long.\"\"\"},\n    {'role': 'user',\n     'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart\"\"\"},\n]"
  },
  {
    "objectID": "slides/basics.html#response-2",
    "href": "slides/basics.html#response-2",
    "title": "Chat Format and Tokens",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)"
  },
  {
    "objectID": "slides/basics.html#helper-function-1",
    "href": "slides/basics.html#helper-function-1",
    "title": "Chat Format and Tokens",
    "section": "Helper function",
    "text": "Helper function\n\nShow how many tokens you are using\n\n\ndef get_completion_and_token_count(messages,\n                                   model=\"gpt-3.5-turbo\",\n                                   temperature=0,\n                                   max_tokens=500):\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens,\n    )\n\n    content = response.choices[0].message[\"content\"]\n\n    token_dict = {\n        'prompt_tokens': response['usage']['prompt_tokens'],\n        'completion_tokens': response['usage']['completion_tokens'],\n        'total_tokens': response['usage']['total_tokens'],\n    }\n\n    return content, token_dict"
  },
  {
    "objectID": "slides/basics.html#example-prompt-1",
    "href": "slides/basics.html#example-prompt-1",
    "title": "Chat Format and Tokens",
    "section": "Example prompt",
    "text": "Example prompt\n\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]\n\nresponse, token_dict = get_completion_and_token_count(messages)"
  },
  {
    "objectID": "slides/basics.html#response-3",
    "href": "slides/basics.html#response-3",
    "title": "Chat Format and Tokens",
    "section": "Response",
    "text": "Response\n\nprint(response)"
  },
  {
    "objectID": "slides/basics.html#token-count-1",
    "href": "slides/basics.html#token-count-1",
    "title": "Chat Format and Tokens",
    "section": "Token count",
    "text": "Token count\n\nprint(token_dict)"
  }
]