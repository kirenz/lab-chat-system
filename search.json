[
  {
    "objectID": "requirements.html",
    "href": "requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "To start this lab, you‚Äôll need:\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.\n\n\n\nPython: Anaconda, Anaconda Environment prompt and Visual Studio Code\nEnvironment: A folder on your machine called prompt, an OpenAI-API key and an environment file with your OpenAI-API keyqu"
  },
  {
    "objectID": "code/notebook.html",
    "href": "code/notebook.html",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#setup",
    "href": "code/notebook.html#setup",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#data",
    "href": "code/notebook.html#data",
    "title": "Notebook",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "tbd."
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "Take a look at the slides tutorial to learn how to use all slide options"
  },
  {
    "objectID": "slide.html#basics",
    "href": "slide.html#basics",
    "title": "Slides",
    "section": "1 Basics",
    "text": "1 Basics\nIn this tutorial, you‚Äôll learn some basic properties of Large Language Models: The Chat Format and Tokens:\n\nüñ•Ô∏è Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome üëã",
    "section": "",
    "text": "Welcome to the lab ‚Äúchat system‚Äù\n\nIn this lab, we will use OpenAI‚Äôs API to leverage Large Language Models (LLMs) like GPT-3.5 Turbo and GPT-4 into Python based chat applications.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you meet all the requirements and have read the lecture slides before you start with the assignments\n\n\nWhat you will learn in this lab:\n\nThis lab is mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI."
  },
  {
    "objectID": "slides/basics.html#python",
    "href": "slides/basics.html#python",
    "title": "Tokens and Chat Format",
    "section": "Python",
    "text": "Python\n\nimport os\nimport openai\nimport tiktoken  # tokenizer\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/basics.html#helper-function",
    "href": "slides/basics.html#helper-function",
    "title": "Tokens and Chat Format",
    "section": "Helper function",
    "text": "Helper function\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "slides/basics.html#example-prompt",
    "href": "slides/basics.html#example-prompt",
    "title": "Tokens and Chat Format",
    "section": "Example prompt",
    "text": "Example prompt\n\nPrompt the model and get a completion\n\n\n\nresponse = get_completion(\"What is the capital of Germany?\")\n\n\n\n\nprint(response)\n\n\n\nThe capital of Germany is Berlin."
  },
  {
    "objectID": "slides/basics.html#intuition",
    "href": "slides/basics.html#intuition",
    "title": "Tokens and Chat Format",
    "section": "Intuition",
    "text": "Intuition"
  },
  {
    "objectID": "slides/basics.html#what-is-a-token",
    "href": "slides/basics.html#what-is-a-token",
    "title": "Tokens and Chat Format",
    "section": "What is a token?",
    "text": "What is a token?\n\nThe GPT family of models process text using tokens\nTokens are common sequences of characters found in text\nThe models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens."
  },
  {
    "objectID": "slides/basics.html#how-long-is-a-token",
    "href": "slides/basics.html#how-long-is-a-token",
    "title": "Tokens and Chat Format",
    "section": "How long is a token?",
    "text": "How long is a token?\n\nOne token generally corresponds to ~4 characters of text\nThis translates to roughly ¬æ of a word (so 100 tokens ~= 75 words)."
  },
  {
    "objectID": "slides/basics.html#tokens-vs-words",
    "href": "slides/basics.html#tokens-vs-words",
    "title": "Tokens and Chat Format",
    "section": "Tokens vs words",
    "text": "Tokens vs words\n\n‚Äúlollipop‚Äù in reverse should be ‚Äúpopillol‚Äù\n\n\n\nresponse = get_completion(\"Take the letters in lollipop \\\nand reverse them\")\nprint(response)\n\n\n\nThe reversed letters of \"lollipop\" are \"pillipol\"."
  },
  {
    "objectID": "slides/basics.html#create-single-tokens",
    "href": "slides/basics.html#create-single-tokens",
    "title": "Tokens and Chat Format",
    "section": "Create single tokens",
    "text": "Create single tokens\n\nresponse = get_completion(\"\"\"Take the letters in \\\nl-o-l-l-i-p-o-p and reverse them\"\"\")\n\n\n\n\n\n\nresponse\n\n\n\n'p-o-p-i-l-l-o-l'"
  },
  {
    "objectID": "slides/basics.html#helper-function-chat-format",
    "href": "slides/basics.html#helper-function-chat-format",
    "title": "Tokens and Chat Format",
    "section": "Helper function (chat format)",
    "text": "Helper function (chat format)\n\nHelper function for chat format\n\n\n\ndef get_completion_from_messages(messages,\n                                 model=\"gpt-3.5-turbo\",\n                                 temperature=0,\n                                 max_tokens=500):\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,  # this is the degree of randomness of the model's output\n        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n    )\n    return response.choices[0].message[\"content\"]"
  },
  {
    "objectID": "slides/basics.html#sokrates-happy-hdm-students",
    "href": "slides/basics.html#sokrates-happy-hdm-students",
    "title": "Tokens and Chat Format",
    "section": "Sokrates & happy HdM students üòä",
    "text": "Sokrates & happy HdM students üòä\n\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]"
  },
  {
    "objectID": "slides/basics.html#response",
    "href": "slides/basics.html#response",
    "title": "Tokens and Chat Format",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n\n\n\nOh, happy student amidst the halls,\nIn Hochschule der Medien's academic thralls,\nWith spirits high and mind engaged,\nIn pursuit of knowledge, never disengaged.\n\nThe books, the lectures, the friends so bright,\nIlluminate the path, brought into sight,\nIn Stuttgart's embrace, where dreams take flight,\nA student's joy, forever igniting the light.\n\nThe journey unfolds, challenges faced,\nBut with passion and fervor, they are embraced,\nFor in each class and project profound,\nWisdom and joy intertwine, astound.\n\nOh, happy student, strong and wise,\nIn Hochschule der Medien, aspirations rise,\nMay your days be filled with learning's delight,\nIn Stuttgart's embrace, forever ignite."
  },
  {
    "objectID": "slides/basics.html#one-sentence-output",
    "href": "slides/basics.html#one-sentence-output",
    "title": "Tokens and Chat Format",
    "section": "One sentence output",
    "text": "One sentence output\n\nmessages = [\n    {'role': 'system',\n     'content': 'All your responses must be \\\none sentence long.'},\n    {'role': 'user',\n     'content': 'write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart'},\n]"
  },
  {
    "objectID": "slides/basics.html#response-1",
    "href": "slides/basics.html#response-1",
    "title": "Tokens and Chat Format",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n\n\n\nIn Stuttgart's halls,\nJoyous student whispers,\nLearning bliss embraces."
  },
  {
    "objectID": "slides/basics.html#sokrates-in-one-sentence",
    "href": "slides/basics.html#sokrates-in-one-sentence",
    "title": "Tokens and Chat Format",
    "section": "Sokrates in one sentence",
    "text": "Sokrates in one sentence\n\n# combined\nmessages = [\n    {'role': 'system',\n     'content': \"\"\"You are an assistant who \\\nresponds in the style of Sokrates. \\\nAll your responses must be one sentence long.\"\"\"},\n    {'role': 'user',\n     'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart\"\"\"},\n]"
  },
  {
    "objectID": "slides/basics.html#response-2",
    "href": "slides/basics.html#response-2",
    "title": "Tokens and Chat Format",
    "section": "Response",
    "text": "Response\n\nresponse = get_completion_from_messages(messages, temperature=1)\nprint(response)\n\n\n\nIn studious bliss, Hochschule's embrace,\nA student's heart, alight with knowledge's grace."
  },
  {
    "objectID": "slides/basics.html#tiktoken",
    "href": "slides/basics.html#tiktoken",
    "title": "Tokens and Chat Format",
    "section": "tiktoken",
    "text": "tiktoken\n\ntiktoken is a fast open-source tokenizer by OpenAI.\nGiven a text string (e.g., ‚Äútiktoken is great!‚Äù) and an encoding (e.g., ‚Äúcl100k_base‚Äù), a tokenizer can split the text string into a list of tokens (e.g., [‚Äút‚Äù, ‚Äúik‚Äù, ‚Äútoken‚Äù, ‚Äù is‚Äù, ‚Äù great‚Äù, ‚Äú!‚Äù]).\nEncodings specify how text is converted into tokens.\nDifferent models use different encodings."
  },
  {
    "objectID": "slides/basics.html#helper-function-1",
    "href": "slides/basics.html#helper-function-1",
    "title": "Tokens and Chat Format",
    "section": "Helper function",
    "text": "Helper function\n\nShow how many tokens you are using\n\n\ndef get_completion_and_token_count(messages,\n                                   model=\"gpt-3.5-turbo\",\n                                   temperature=0,\n                                   max_tokens=500):\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=temperature,\n        max_tokens=max_tokens,\n    )\n\n    content = response.choices[0].message[\"content\"]\n\n    token_dict = {\n        'prompt_tokens': response['usage']['prompt_tokens'],\n        'completion_tokens': response['usage']['completion_tokens'],\n        'total_tokens': response['usage']['total_tokens'],\n    }\n\n    return content, token_dict"
  },
  {
    "objectID": "slides/basics.html#example-prompt-1",
    "href": "slides/basics.html#example-prompt-1",
    "title": "Tokens and Chat Format",
    "section": "Example prompt",
    "text": "Example prompt\n\nmessages = [\n    {'role': 'system',  # overall tone/behavior of assistant\n     'content': \"\"\"You are an assistant who\\\n responds in the style of Sokrates.\"\"\"},\n    {'role': 'user',\n        'content': \"\"\"write me a very short poem\\\n about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n]\n\nresponse, token_dict = get_completion_and_token_count(messages)"
  },
  {
    "objectID": "slides/basics.html#response-3",
    "href": "slides/basics.html#response-3",
    "title": "Tokens and Chat Format",
    "section": "Response",
    "text": "Response\n\nprint(response)\n\n\n\nOh, a student at Hochschule der Medien Stuttgart,\nWith joy in their heart, their passion unfurled.\nIn lectures they learn, their minds ever bright,\nSeeking knowledge, embracing the light.\n\nAmongst fellow scholars, they find their place,\nSharing ideas, with smiles on their face.\nIn libraries they delve, books as their guide,\nExpanding horizons, with each page they stride.\n\nWith professors as mentors, guiding their way,\nThey grow and they flourish, day after day.\nIn projects they thrive, creativity soars,\nA happy student, forever exploring new shores.\n\nOh, Hochschule der Medien Stuttgart, a place so grand,\nWhere dreams are nurtured, where futures expand.\nA happy student, forever grateful, they'll be,\nFor the knowledge gained, and the memories set free."
  },
  {
    "objectID": "slides/basics.html#token-count-1",
    "href": "slides/basics.html#token-count-1",
    "title": "Tokens and Chat Format",
    "section": "Token count",
    "text": "Token count\n\nprint(token_dict)\n\n\n\n{'prompt_tokens': 43, 'completion_tokens': 167, 'total_tokens': 210}"
  }
]