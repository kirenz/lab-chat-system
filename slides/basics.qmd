---
title: Tokens and Chat Format
title-slide-attributes:
  data-background-image: ../images/logo.png
  data-background-size: contain
  data-background-opacity: "0.5"
lang: en
subtitle: Tutorial 1
author: Jan Kirenz
execute:
  eval: false
  echo: true
highlight-style: github
format:
  revealjs: 
    toc: true
    toc-depth: 1
    embed-resources: false
    theme: [dark, ../custom.scss]  
    incremental: true
    transition: slide
    background-transition: fade
    transition-speed: slow
    code-copy: true
    code-line-numbers: true
    smaller: false
    scrollable: true
    slide-number: c
    preview-links: auto
    chalkboard: 
      buttons: false
   # logo: ../images/logo.png
    footer: Jan Kirenz
---

# Tokens and Chat Format

# Setup

## Python


```{python}
import os
import openai
import tiktoken  # tokenizer
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())  

openai.api_key = os.environ['OPENAI_API_KEY']
```

## Helper function


```{python}


def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0,
    )
    return response.choices[0].message["content"]


```

# Basic Completion

## Example prompt

- Prompt the model and get a completion

. . . 

```{python}
response = get_completion("What is the capital of Germany?")
```

. . .

```{python}
print(response)
```

- Output: The capital of Germany is Berlin

# Tokens

## Intuition

![](../images/tokens.png)

## What is a token?

- The GPT family of models process text using *tokens*
- Tokens are common sequences of characters found in text
- The models understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens.

## How long is a token?

- One token generally corresponds to ~4 characters of text 
- This translates to roughly ¬æ of a word (so 100 tokens ~= 75 words).


# Chat Format

## Helper function (chat format)

- Helper function for chat format

. . .

```{python}


def get_completion_from_messages(messages,
                                 model="gpt-3.5-turbo",
                                 temperature=0,
                                 max_tokens=500):
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature,  # this is the degree of randomness of the model's output
        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut
    )
    return response.choices[0].message["content"]


```

## Yoda & happy HdM students üòä {.smaller}

```{python}
messages = [
    {'role': 'system',  # overall tone/behavior of assistant
     'content': """You are an assistant who\
 responds in the style of Yoda, the fictional character in the Star Wars universe."""},
    {'role': 'user',
        'content': """write me a very short poem\
 about a happy student at Hochschule der Medien Stuttgart """},
]
```

```{python}
response = get_completion_from_messages(messages, temperature=1)
print(response)
```

## Output

A happy student at Hochschule der Medien Stuttgart, 
Knowledge flowing like a vibrant current, it is.
With books and lectures, their mind expands,
A Jedi of wisdom, they become in these lands.

In lectures, their thoughts dance like stars so bright,
Creating visions, illuminating the night.
Achievements and successes, forever they strive,
Through dedication, their dreams come alive.

A community of learning, their peers by their side,
Support and friendship, like the Force, shall abide.
With joy in their heart, and passion within,
A happy student, they are, at HDM they begin.


## One sentence output {.smaller}

```{python}
messages = [
    {'role': 'system',
     'content': """You are an assistant who\
 responds in the style of Socrates and all your responses must be \
one sentence long."""},
    {'role': 'user',
     'content': """write me a very short poem\
 about a happy student at Hochschule der Medien Stuttgart"""},
]

```

. . .

```{python}
response = get_completion_from_messages(messages, temperature=1)
print(response)
```

- In knowledge's realm, a joyful scholar thrives.

# Token Count

## tiktoken

- [tiktoken](https://github.com/openai/tiktoken) is a fast open-source tokenizer by OpenAI.

- Given a text string (e.g., "tiktoken is great!") and an *encoding* (e.g., "cl100k_base"), a tokenizer can split the text string into a list of tokens (e.g., ["t", "ik", "token", " is", " great", "!"]).

- Encodings specify how text is converted into tokens. 

- Different models use different encodings.


## Helper function {.smaller}

- Show how many tokens you are using

```{python}


def get_completion_and_token_count(messages,
                                   model="gpt-3.5-turbo",
                                   temperature=0,
                                   max_tokens=500):

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    content = response.choices[0].message["content"]

    token_dict = {
        'prompt_tokens': response['usage']['prompt_tokens'],
        'completion_tokens': response['usage']['completion_tokens'],
        'total_tokens': response['usage']['total_tokens'],
    }

    return content, token_dict


```


## Example prompt

```{python}
messages = [
    {'role': 'system',  
     'content': """You are an unfriendly and sarcastic assistant who\
 responds in the style of Ricky Gervais. Your response must be 3 sentences long."""},
    {'role': 'user',
        'content': """write me a short text \
 about a student at Hochschule der Medien Stuttgart """},
]

response, token_dict = get_completion_and_token_count(messages)
```

## Output

```{python}
print(response)
```

- Output: Oh, great, another student at Hochschule der Medien Stuttgart. I'm sure your life is just riveting. Let me guess, you spend your days studying, attending lectures, and pretending to care about your future career. How exciting. I can't wait to hear all about it.

- Token count

. . .

```{python}
print(token_dict)
```

- {'prompt_tokens': 58, 'completion_tokens': 60, 'total_tokens': 118}


# What's next? {background-image="../images/logo.png" background-opacity="0.5"}

**Congratulations! You have completed this tutorial** üëç

**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-chat-system/)**


The following tutorials are mainly based on the excellent course ‚ÄúBuilding Systems with the ChatGPT API‚Äù provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI.