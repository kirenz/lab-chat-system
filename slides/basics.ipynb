{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Language Models, the Chat Format and Tokens\n",
        "lang: en\n",
        "subtitle: Tutorial 1\n",
        "author: Jan Kirenz\n",
        "execute:\n",
        "  eval: true\n",
        "  echo: true\n",
        "highlight-style: github\n",
        "format:\n",
        "  revealjs: \n",
        "    toc: true\n",
        "    toc-depth: 1\n",
        "    embed-resources: false\n",
        "    theme: [dark, ../custom.scss]  \n",
        "    incremental: true\n",
        "    transition: slide\n",
        "    background-transition: fade\n",
        "    transition-speed: slow\n",
        "    code-copy: true\n",
        "    code-line-numbers: true\n",
        "    smaller: false\n",
        "    scrollable: true\n",
        "    slide-number: c\n",
        "    preview-links: auto\n",
        "    chalkboard: \n",
        "      buttons: false\n",
        "   #logo: images/logo.png\n",
        "    footer: Jan Kirenz\n",
        "---"
      ],
      "id": "c4a66929"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "\n",
        "## Python\n"
      ],
      "id": "9d819609"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())  # read local .env file\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "id": "7267a668",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper function\n"
      ],
      "id": "5f5e8637"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n"
      ],
      "id": "a4675ece",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic Language Model\n",
        "\n",
        "## Standard completion\n",
        "\n",
        "- Prompt the model and get a completion\n"
      ],
      "id": "4f458abb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "response = get_completion(\"What is the capital of France?\")"
      ],
      "id": "fb6b83d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n"
      ],
      "id": "43c4fc21"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "print(response)"
      ],
      "id": "cf0fb810",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokens\n"
      ],
      "id": "8a643942"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response = get_completion(\"Take the letters in lollipop \\\n",
        "and reverse them\")\n",
        "print(response)"
      ],
      "id": "fe8fc700",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- \"lollipop\" in reverse should be \"popillol\"\n",
        "\n",
        "## Explicit tokens\n"
      ],
      "id": "973ae712"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response = get_completion(\"\"\"Take the letters in \\\n",
        "l-o-l-l-i-p-o-p and reverse them\"\"\")"
      ],
      "id": "92818961",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n"
      ],
      "id": "eb4681c1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response"
      ],
      "id": "2df63908",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chat Format\n",
        "\n",
        "## Helper function (chat format)\n",
        "\n",
        "- Helper function for chat format\n"
      ],
      "id": "63b7d785"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_completion_from_messages(messages,\n",
        "                                 model=\"gpt-3.5-turbo\",\n",
        "                                 temperature=0,\n",
        "                                 max_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,  # this is the degree of randomness of the model's output\n",
        "        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n"
      ],
      "id": "2bfcb058",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Message example Sokrates\n"
      ],
      "id": "693b6f9b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = [\n",
        "    {'role': 'system',  # overall tone/behavior of assistant\n",
        "     'content': \"\"\"You are an assistant who\\\n",
        " responds in the style of Sokrates.\"\"\"},\n",
        "    {'role': 'user',\n",
        "        'content': \"\"\"write me a very short poem\\\n",
        " about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n",
        "]"
      ],
      "id": "37504837",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Response\n"
      ],
      "id": "d6d5a6f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "id": "ee24925f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Message example one sentence\n"
      ],
      "id": "b604fd05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = [\n",
        "    {'role': 'system',\n",
        "     'content': 'All your responses must be \\\n",
        "one sentence long.'},\n",
        "    {'role': 'user',\n",
        "     'content': 'write me a very short poem\\\n",
        " about a happy student at Hochschule der Medien Stuttgart'},\n",
        "]"
      ],
      "id": "7c5d30fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Response\n"
      ],
      "id": "e9eb86f0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "id": "14a35d9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Message example Sokrates, one sentence\n"
      ],
      "id": "7436b9c9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "# combined\n",
        "messages = [\n",
        "    {'role': 'system',\n",
        "     'content': \"\"\"You are an assistant who \\\n",
        "responds in the style of Sokrates. \\\n",
        "All your responses must be one sentence long.\"\"\"},\n",
        "    {'role': 'user',\n",
        "     'content': \"\"\"write me a story about a happy carrot\"\"\"},\n",
        "]"
      ],
      "id": "dd675337",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Response\n"
      ],
      "id": "365c8106"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "id": "6400421d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Token Count\n",
        "\n",
        "## Helper function {.smaller}\n",
        "\n",
        "- Show how many tokens you are using\n"
      ],
      "id": "0683916f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_completion_and_token_count(messages,\n",
        "                                   model=\"gpt-3.5-turbo\",\n",
        "                                   temperature=0,\n",
        "                                   max_tokens=500):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message[\"content\"]\n",
        "\n",
        "    token_dict = {\n",
        "        'prompt_tokens': response['usage']['prompt_tokens'],\n",
        "        'completion_tokens': response['usage']['completion_tokens'],\n",
        "        'total_tokens': response['usage']['total_tokens'],\n",
        "    }\n",
        "\n",
        "    return content, token_dict\n"
      ],
      "id": "8f3545fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example message\n"
      ],
      "id": "f34fa8ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "messages = [\n",
        "    {'role': 'system',  # overall tone/behavior of assistant\n",
        "     'content': \"\"\"You are an assistant who\\\n",
        " responds in the style of Sokrates.\"\"\"},\n",
        "    {'role': 'user',\n",
        "        'content': \"\"\"write me a very short poem\\\n",
        " about a happy student at Hochschule der Medien Stuttgart \"\"\"},\n",
        "]\n",
        "\n",
        "response, token_dict = get_completion_and_token_count(messages)"
      ],
      "id": "e625ef3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Response \n"
      ],
      "id": "89545ecf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "print(response)"
      ],
      "id": "e1e23696",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n"
      ],
      "id": "eed22b1e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "output-location": "fragment"
      },
      "source": [
        "print(token_dict)"
      ],
      "id": "1566fe83",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}