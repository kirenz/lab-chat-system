---
title: "Slides"
number-sections: true
---

*The following tutorials are mainly based on an excellent course provided by Isa Fulford from OpenAI and Andrew Ng from DeepLearning.AI.*

For cost reasons we mainly use OpenAI's `gpt-3.5-turbo` model in our tutorials. However, you can simply replace `model="gpt-3.5-turbo"` with `model="gpt-4"` in the helper function. Note the [price difference](https://openai.com/pricing) between the two models.

::: {.callout-note appearance="simple"}
Take a look at the [slides tutorial](https://kirenz.github.io/lab-toolkit/slides/slides.html#/title-slide) to learn how to use all slide options 

:::


## Basics: Tokens and chat format

In this tutorial, you'll learn some basic properties of Large Language Models: Tokens and the chat format:

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/basics.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/basics.ipynb)
:::


## Classification 

Learn how to classify different customer queries:

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/classification.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/classification.ipynb)
:::

## Moderation

The moderations endpoint is a tool you can use to check whether content complies with our usage policies:


::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/moderation.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/moderation.ipynb)
:::

## Chain of Thought Reasoning

Chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding:

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/reasoning.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/reasoning.ipynb)
:::

## Chaining Prompts

Prompt Chaining is a technique of connecting multiple tasks to generate complex content by breaking down a large generative task into smaller, more manageable pieces. Examples of prompt chaining are generating product descriptions, creating personalized email campaigns, and generating complex chatbot responses.


::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/chaining.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/chaining.ipynb)
:::

## Check Model Output 

Ask the model to verify its own outputs:

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/outputcheck.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/outputcheck.ipynb)
:::

## Build an End-to-End System

This puts together the chain of prompts that you saw throughout the tutorials:


::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/system.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/system.ipynb)
- [products.json](/slides/products.json)
- [utils.py](/slides/utils.py)
:::


## Evaluation

Evaluate LLM responses when there is a single "right answer".

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/evaluation.qmd)
- [💻 evaluation.ipynb](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/evaluation.ipynb)
- [products.json](/slides/products.json)
- [utils.py](/slides/utils_2.py)
:::

## Evaluation Part 2

Evaluate LLM responses where there isn't a single "right answer."

::: {.callout-tip appearance="simple" icon=false}
- [🖥️ Presentation](/slides/evaluation_2.qmd)
- [💻 Jupyter Notebook](https://colab.research.google.com/github/kirenz/lab-chat-system/blob/main/code/evaluation_2.ipynb)
:::